#!/usr/bin/env python3
# script: assemble_architecture.py

import os
import json
import subprocess
from pathlib import Path
from typing import Dict, List, Any, Set, Tuple
import ast
import re
import logging

class ArchitectureMapper:
    """Ø±Ø§Ø³Ù… Ø®Ø±Ø§Ø¦Ø· Ø§Ù„Ù…Ø¹Ù…Ø§Ø±ÙŠØ© ÙˆØ§Ù„ØªØ¨Ø¹ÙŠØ§Øª"""

    def __init__(self, repo_path: str, output_dir: str):
        self.repo_path = Path(repo_path)
        self.output_dir = Path(output_dir)
        self.logger = logging.getLogger(__name__)

    def generate_dependency_graph(self) -> Dict[str, Any]:
        """Ø¥Ù†ØªØ§Ø¬ Ø®Ø±ÙŠØ·Ø© Ø§Ù„ØªØ¨Ø¹ÙŠØ§Øª"""
        self.logger.info("ðŸ—ºï¸ Ø¥Ù†ØªØ§Ø¬ Ø®Ø±ÙŠØ·Ø© Ø§Ù„ØªØ¨Ø¹ÙŠØ§Øª...")

        graph_data = {
            "modules": {},
            "dependencies": [],
            "circular_dependencies": [],
            "metrics": {
                "total_modules": 0,
                "total_connections": 0,
                "max_depth": 0,
                "coupling_score": 0.0
            }
        }

        # ØªØ­Ù„ÙŠÙ„ JavaScript/TypeScript
        if self._has_js_project():
            js_graph = self._analyze_js_dependencies()
            graph_data.update(js_graph)

        # ØªØ­Ù„ÙŠÙ„ Python
        elif self._has_python_project():
            python_graph = self._analyze_python_dependencies()
            graph_data.update(python_graph)

        # Ø¥Ù†ØªØ§Ø¬ Ù…Ø®Ø·Ø· Ø¨ØµØ±ÙŠ
        self._generate_visual_graph(graph_data)

        # Ø­ÙØ¸ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        with open(self.output_dir / "artifacts/assemble/dependency_graph.json", "w") as f:
            json.dump(graph_data, f, indent=2, ensure_ascii=False)

        return graph_data

    def _has_js_project(self) -> bool:
        """ÙØ­Øµ ÙˆØ¬ÙˆØ¯ Ù…Ø´Ø±ÙˆØ¹ JavaScript/TypeScript"""
        return (self.repo_path / "package.json").exists()

    def _has_python_project(self) -> bool:
        """ÙØ­Øµ ÙˆØ¬ÙˆØ¯ Ù…Ø´Ø±ÙˆØ¹ Python"""
        return (
            (self.repo_path / "setup.py").exists() or
            (self.repo_path / "requirements.txt").exists() or
            (self.repo_path / "pyproject.toml").exists()
        )

    def _analyze_js_dependencies(self) -> Dict[str, Any]:
        """ØªØ­Ù„ÙŠÙ„ ØªØ¨Ø¹ÙŠØ§Øª JavaScript/TypeScript"""
        try:
            # Ø§Ø³ØªØ®Ø¯Ø§Ù… madge Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªØ¨Ø¹ÙŠØ§Øª
            result = subprocess.run(
                ["npx", "madge", "--json", str(self.repo_path / "src")],
                capture_output=True,
                text=True,
                timeout=120,
                cwd=self.repo_path
            )

            if result.returncode == 0:
                madge_data = json.loads(result.stdout)

                # ØªØ­ÙˆÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª madge Ø¥Ù„Ù‰ ØªÙ†Ø³ÙŠÙ‚ Ù…ÙˆØ­Ø¯
                modules = {}
                dependencies = []

                for module, deps in madge_data.items():
                    module_name = Path(module).stem
                    modules[module_name] = {
                        "path": module,
                        "type": "module",
                        "dependencies": deps,
                        "dependents": []
                    }

                    for dep in deps:
                        dep_name = Path(dep).stem
                        dependencies.append({
                            "from": module_name,
                            "to": dep_name,
                            "type": "import"
                        })

                # Ø­Ø³Ø§Ø¨ Ø§Ù„ØªØ¨Ø¹ÙŠØ§Øª Ø§Ù„Ø¹ÙƒØ³ÙŠØ©
                for dep in dependencies:
                    if dep["to"] in modules:
                        modules[dep["to"]]["dependents"].append(dep["from"])

                # ÙƒØ´Ù Ø§Ù„ØªØ¨Ø¹ÙŠØ§Øª Ø§Ù„Ø¯ÙˆØ±ÙŠØ©
                circular = self._detect_circular_dependencies(dependencies)

                return {
                    "modules": modules,
                    "dependencies": dependencies,
                    "circular_dependencies": circular,
                    "metrics": self._calculate_dependency_metrics(modules, dependencies)
                }

        except (subprocess.TimeoutExpired, json.JSONDecodeError, FileNotFoundError):
            self.logger.warning("âš ï¸ ÙØ´Ù„ ØªØ­Ù„ÙŠÙ„ ØªØ¨Ø¹ÙŠØ§Øª JavaScript")

        return {"modules": {}, "dependencies": [], "circular_dependencies": []}

    def _analyze_python_dependencies(self) -> Dict[str, Any]:
        """ØªØ­Ù„ÙŠÙ„ ØªØ¨Ø¹ÙŠØ§Øª Python"""
        modules = {}
        dependencies = []

        # ÙØ­Øµ Ù…Ù„ÙØ§Øª Python
        for py_file in self.repo_path.rglob("*.py"):
            if any(part.startswith('.') for part in py_file.parts):
                continue

            module_name = py_file.stem
            relative_path = py_file.relative_to(self.repo_path)

            try:
                with open(py_file, 'r', encoding='utf-8') as f:
                    content = f.read()

                # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù€ imports
                tree = ast.parse(content)
                imports = self._extract_python_imports(tree)

                modules[module_name] = {
                    "path": str(relative_path),
                    "type": "python_module",
                    "dependencies": imports,
                    "dependents": [],
                    "functions": self._extract_python_functions(tree),
                    "classes": self._extract_python_classes(tree)
                }

                for imp in imports:
                    dependencies.append({
                        "from": module_name,
                        "to": imp,
                        "type": "import"
                    })

            except (SyntaxError, UnicodeDecodeError) as e:
                self.logger.warning(f"âš ï¸ ØªØ¹Ø°Ø± ØªØ­Ù„ÙŠÙ„ {py_file}: {e}")

        # Ø­Ø³Ø§Ø¨ Ø§Ù„ØªØ¨Ø¹ÙŠØ§Øª Ø§Ù„Ø¹ÙƒØ³ÙŠØ©
        for dep in dependencies:
            if dep["to"] in modules:
                modules[dep["to"]]["dependents"].append(dep["from"])

        circular = self._detect_circular_dependencies(dependencies)

        return {
            "modules": modules,
            "dependencies": dependencies,
            "circular_dependencies": circular,
            "metrics": self._calculate_dependency_metrics(modules, dependencies)
        }

    def _extract_python_imports(self, tree: ast.AST) -> List[str]:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù€ imports Ù…Ù† AST"""
        imports = []

        for node in ast.walk(tree):
            if isinstance(node, ast.Import):
                for alias in node.names:
                    imports.append(alias.name.split('.')[0])
            elif isinstance(node, ast.ImportFrom):
                if node.module:
                    imports.append(node.module.split('.')[0])

        return list(set(imports))

    def _extract_python_functions(self, tree: ast.AST) -> List[str]:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø¯ÙˆØ§Ù„"""
        functions = []

        for node in ast.walk(tree):
            if isinstance(node, ast.FunctionDef):
                functions.append(node.name)

        return functions

    def _extract_python_classes(self, tree: ast.AST) -> List[str]:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„ÙØ¦Ø§Øª"""
        classes = []

        for node in ast.walk(tree):
            if isinstance(node, ast.ClassDef):
                classes.append(node.name)

        return classes

    def _detect_circular_dependencies(self, dependencies: List[Dict]) -> List[List[str]]:
        """ÙƒØ´Ù Ø§Ù„ØªØ¨Ø¹ÙŠØ§Øª Ø§Ù„Ø¯ÙˆØ±ÙŠØ©"""
        # Ø¨Ù†Ø§Ø¡ Ø§Ù„Ø±Ø³Ù… Ø§Ù„Ø¨ÙŠØ§Ù†ÙŠ
        graph = {}
        for dep in dependencies:
            if dep["from"] not in graph:
                graph[dep["from"]] = []
            graph[dep["from"]].append(dep["to"])

        # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ø¯ÙˆØ±Ø§Øª
        visited = set()
        rec_stack = set()
        cycles = []

        def dfs(node: str, path: List[str]) -> None:
            if node in rec_stack:
                # Ø¹Ø«Ø±Ù†Ø§ Ø¹Ù„Ù‰ Ø¯ÙˆØ±Ø©
                cycle_start = path.index(node)
                cycle = path[cycle_start:] + [node]
                cycles.append(cycle)
                return

            if node in visited:
                return

            visited.add(node)
            rec_stack.add(node)
            path.append(node)

            for neighbor in graph.get(node, []):
                dfs(neighbor, path[:])

            rec_stack.remove(node)
            path.pop()

        for node in graph:
            if node not in visited:
                dfs(node, [])

        return cycles

    def _calculate_dependency_metrics(self, modules: Dict, dependencies: List[Dict]) -> Dict[str, Any]:
        """Ø­Ø³Ø§Ø¨ Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„ØªØ¨Ø¹ÙŠØ§Øª"""
        if not modules:
            return {"total_modules": 0, "total_connections": 0, "coupling_score": 0.0}

        total_modules = len(modules)
        total_connections = len(dependencies)

        # Ø­Ø³Ø§Ø¨ Ù…ØªÙˆØ³Ø· Ø§Ù„Ù€ coupling
        coupling_scores = []
        for module_name, module_data in modules.items():
            efferent = len(module_data.get("dependencies", []))  # ØµØ§Ø¯Ø±
            afferent = len(module_data.get("dependents", []))    # ÙˆØ§Ø±Ø¯

            if efferent + afferent > 0:
                instability = efferent / (efferent + afferent)
                coupling_scores.append(instability)

        avg_coupling = sum(coupling_scores) / len(coupling_scores) if coupling_scores else 0.0

        return {
            "total_modules": total_modules,
            "total_connections": total_connections,
            "average_coupling": round(avg_coupling, 3),
            "coupling_distribution": {
                "low": len([s for s in coupling_scores if s < 0.3]),
                "medium": len([s for s in coupling_scores if 0.3 <= s < 0.7]),
                "high": len([s for s in coupling_scores if s >= 0.7])
            }
        }

    def _generate_visual_graph(self, graph_data: Dict[str, Any]) -> None:
        """Ø¥Ù†ØªØ§Ø¬ Ù…Ø®Ø·Ø· Ø¨ØµØ±ÙŠ Ù„Ù„ØªØ¨Ø¹ÙŠØ§Øª"""
        try:
            import matplotlib.pyplot as plt
            import networkx as nx

            # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø±Ø³Ù… Ø§Ù„Ø¨ÙŠØ§Ù†ÙŠ
            G = nx.DiGraph()

            # Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø¹Ù‚Ø¯
            for module_name in graph_data["modules"].keys():
                G.add_node(module_name)

            # Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø­ÙˆØ§Ù
            for dep in graph_data["dependencies"]:
                G.add_edge(dep["from"], dep["to"])

            # Ø±Ø³Ù… Ø§Ù„Ù…Ø®Ø·Ø·
            plt.figure(figsize=(15, 10))
            pos = nx.spring_layout(G, k=1, iterations=50)

            # Ø±Ø³Ù… Ø§Ù„Ø¹Ù‚Ø¯
            nx.draw_networkx_nodes(G, pos, node_color='lightblue',
                                 node_size=1000, alpha=0.7)

            # Ø±Ø³Ù… Ø§Ù„Ø­ÙˆØ§Ù
            nx.draw_networkx_edges(G, pos, edge_color='gray',
                                 arrows=True, arrowsize=20)

            # Ø¥Ø¶Ø§ÙØ© Ø§Ù„ØªØ³Ù…ÙŠØ§Øª
            nx.draw_networkx_labels(G, pos, font_size=8)

            plt.title("Ø®Ø±ÙŠØ·Ø© Ø§Ù„ØªØ¨Ø¹ÙŠØ§Øª", fontsize=16)
            plt.axis('off')
            plt.tight_layout()

            # Ø­ÙØ¸ Ø§Ù„Ù…Ø®Ø·Ø·
            output_path = self.output_dir / "artifacts/assemble/dependency_graph.png"
            plt.savefig(output_path, dpi=300, bbox_inches='tight')
            plt.close()

            self.logger.info(f"âœ… ØªÙ… Ø­ÙØ¸ Ø§Ù„Ù…Ø®Ø·Ø· Ø§Ù„Ø¨ØµØ±ÙŠ: {output_path}")

        except ImportError:
            self.logger.warning("âš ï¸ matplotlib Ø£Ùˆ networkx ØºÙŠØ± Ù…ØªÙˆÙØ± Ù„Ø¥Ù†ØªØ§Ø¬ Ø§Ù„Ù…Ø®Ø·Ø·Ø§Øª Ø§Ù„Ø¨ØµØ±ÙŠØ©")
        except Exception as e:
            self.logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø¥Ù†ØªØ§Ø¬ Ø§Ù„Ù…Ø®Ø·Ø· Ø§Ù„Ø¨ØµØ±ÙŠ: {e}")

    def analyze_api_interfaces(self) -> Dict[str, Any]:
        """ØªØ­Ù„ÙŠÙ„ ÙˆØ§Ø¬Ù‡Ø§Øª API"""
        self.logger.info("ðŸ”Œ ØªØ­Ù„ÙŠÙ„ ÙˆØ§Ø¬Ù‡Ø§Øª API...")

        apis = {
            "rest_endpoints": [],
            "graphql_schemas": [],
            "grpc_services": [],
            "openapi_specs": []
        }

        # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ù…Ù„ÙØ§Øª OpenAPI/Swagger
        openapi_files = list(self.repo_path.rglob("*openapi*.yml")) + \
                       list(self.repo_path.rglob("*swagger*.yml")) + \
                       list(self.repo_path.rglob("*openapi*.yaml")) + \
                       list(self.repo_path.rglob("*swagger*.yaml"))

        for api_file in openapi_files:
            try:
                with open(api_file, 'r', encoding='utf-8') as f:
                    content = f.read()
                    apis["openapi_specs"].append({
                        "file": str(api_file.relative_to(self.repo_path)),
                        "size": len(content),
                        "endpoints_count": content.count("paths:")
                    })
            except Exception as e:
                self.logger.warning(f"âš ï¸ ØªØ¹Ø°Ø± Ù‚Ø±Ø§Ø¡Ø© {api_file}: {e}")

        # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ù…Ù„ÙØ§Øª GraphQL
        graphql_files = list(self.repo_path.rglob("*.graphql")) + \
                       list(self.repo_path.rglob("*.gql"))

        for gql_file in graphql_files:
            try:
                with open(gql_file, 'r', encoding='utf-8') as f:
                    content = f.read()
                    apis["graphql_schemas"].append({
                        "file": str(gql_file.relative_to(self.repo_path)),
                        "size": len(content),
                        "types_count": content.count("type "),
                        "queries_count": content.count("Query"),
                        "mutations_count": content.count("Mutation")
                    })
            except Exception as e:
                self.logger.warning(f"âš ï¸ ØªØ¹Ø°Ø± Ù‚Ø±Ø§Ø¡Ø© {gql_file}: {e}")

        # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ù…Ù„ÙØ§Øª Proto (gRPC)
        proto_files = list(self.repo_path.rglob("*.proto"))

        for proto_file in proto_files:
            try:
                with open(proto_file, 'r', encoding='utf-8') as f:
                    content = f.read()
                    apis["grpc_services"].append({
                        "file": str(proto_file.relative_to(self.repo_path)),
                        "size": len(content),
                        "services_count": content.count("service "),
                        "messages_count": content.count("message ")
                    })
            except Exception as e:
                self.logger.warning(f"âš ï¸ ØªØ¹Ø°Ø± Ù‚Ø±Ø§Ø¡Ø© {proto_file}: {e}")

        # ÙƒØ´Ù REST endpoints Ù…Ù† Ø§Ù„ÙƒÙˆØ¯
        rest_endpoints = self._extract_rest_endpoints()
        apis["rest_endpoints"] = rest_endpoints

        # Ø­ÙØ¸ ØªØ­Ù„ÙŠÙ„ APIs
        with open(self.output_dir / "artifacts/assemble/api_analysis.json", "w") as f:
            json.dump(apis, f, indent=2, ensure_ascii=False)

        return apis

    def _extract_rest_endpoints(self) -> List[Dict[str, Any]]:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ REST endpoints Ù…Ù† Ø§Ù„ÙƒÙˆØ¯"""
        endpoints = []

        # Ø£Ù†Ù…Ø§Ø· Ø´Ø§Ø¦Ø¹Ø© Ù„Ù€ REST endpoints
        patterns = [
            r'@app\.route\(["\']([^"\']+)["\'].*methods=\[([^\]]+)\]',  # Flask
            r'@RequestMapping\(["\']([^"\']+)["\'].*method\s*=\s*RequestMethod\.(\w+)',  # Spring
            r'router\.(get|post|put|delete|patch)\(["\']([^"\']+)["\']',  # Express.js
            r'@(GET|POST|PUT|DELETE|PATCH)\(["\']([^"\']+)["\']',  # JAX-RS
        ]

        # ÙØ­Øµ Ù…Ù„ÙØ§Øª Ø§Ù„ÙƒÙˆØ¯
        for code_file in self.repo_path.rglob("*"):
            if code_file.suffix in ['.py', '.java', '.js', '.ts', '.kt']:
                try:
                    with open(code_file, 'r', encoding='utf-8') as f:
                        content = f.read()

                        for pattern in patterns:
                            matches = re.finditer(pattern, content, re.IGNORECASE)
                            for match in matches:
                                if len(match.groups()) >= 2:
                                    path = match.group(1) if match.group(1).startswith('/') else match.group(2)
                                    method = match.group(2) if match.group(1).startswith('/') else match.group(1)

                                    endpoints.append({
                                        "path": path,
                                        "method": method.upper(),
                                        "file": str(code_file.relative_to(self.repo_path)),
                                        "line": content[:match.start()].count('\n') + 1
                                    })

                except (UnicodeDecodeError, Exception):
                    continue

        return endpoints

def main():
    """Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©"""
    import sys

    if len(sys.argv) < 3:
        print("Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…: python assemble_architecture.py <repo_path> <output_dir>")
        sys.exit(1)

    repo_path = sys.argv[1]
    output_dir = sys.argv[2]

    mapper = ArchitectureMapper(repo_path, output_dir)

    # ØªØ´ØºÙŠÙ„ Ø§Ù„ØªØ­Ù„ÙŠÙ„
    mapper.generate_dependency_graph()
    mapper.analyze_api_interfaces()

    print("âœ… ØªÙ…Øª Ù…Ø±Ø­Ù„Ø© Ø§Ù„ØªØ¬Ù…ÙŠØ¹ Ø¨Ù†Ø¬Ø§Ø­")

if __name__ == "__main__":
    main()